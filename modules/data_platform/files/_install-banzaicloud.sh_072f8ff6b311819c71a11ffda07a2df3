
#!/bin/bash
cat <<EOF > /databricks/spark/conf/metrics.properties
# Enable Prometheus for all instances by class name
*.sink.prometheus.class=org.apache.spark.banzaicloud.metrics.sink.PrometheusSink
# Prometheus pushgateway address
*.sink.prometheus.pushgateway-address-protocol=http
*.sink.prometheus.pushgateway-address=35.223.225.182
# Support for JMX Collector (version 2.3-2.0.0 +)
*.sink.prometheus.enable-dropwizard-collector=true
*.sink.prometheus.enable-jmx-collector=true
*.sink.prometheus.jmx-collector-config=/databricks/spark/conf/jmxCollector.yaml
# Enable HostName in Instance instead of Appid (Default value is false i.e. instance=${appid})
*.sink.prometheus.enable-hostname-in-instance=true
# Enable JVM metrics source for all instances by class name
*.sink.jmx.class=org.apache.spark.metrics.sink.JmxSink
*.source.jvm.class=org.apache.spark.metrics.source.JvmSource
EOF
cat >/databricks/driver/conf/00-custom-spark.conf <<EOF
[driver] {
#  spark.metrics.namespace = "${DB_CLUSTER_NAME}"
  spark.sql.streaming.metricsEnabled = "true"
  spark.metrics.appStatusSource.enabled = "true"
}
EOF
cat >/databricks/spark/conf/jmxCollector.yaml << EOF
    lowercaseOutputName: false
    lowercaseOutputLabelNames: false
    whitelistObjectNames: ["*:*"]
EOF
wget --quiet -O /databricks/jars/spark-metrics-assembly-3.1-1.0.0.jar https://github.com/dlyle65535/spark-metrics/raw/3.1-1.0.0/maven-repo/releases/com/banzaicloud/spark-metrics_3.1/3.1-1.0.0/spark-metrics-assembly-3.1-1.0.0.jar
